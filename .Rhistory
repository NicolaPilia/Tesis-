#Converting foreign characters into english
library(gsubfn)
cons<-gsub("Ç","c",cons)
cons<-gsub("¸",",",cons)
cons<-gsub("ƒ","f",cons)
cons<-gsub("ÿ","y",cons)
cons<-gsub("¶","",cons)
cons<-gsub("½","",cons)
pros<-gsub("Ç","c",pros)
pros<-gsub("¸",",",pros)
pros<-gsub("ƒ","f",pros)
pros<-gsub("ÿ","y",pros)
pros<-gsub("¶","",pros)
cons<-gsub("½","",pros)
View(pros)
pros<-gsub("½","",pros)
cons<-gsub("½","",cons)
View(cons)
pros<-pros[-c(809,810)]
cons<-cons[-c(809,810)]
corp_p<-Corpus(VectorSource(pros))
library(tm)
corp_p<-Corpus(VectorSource(pros))
corp_c<-Corpus(VectorSource(cons))
corp_p<-tm_map(corp_p, stripWhitespace)
corp_p<-tm_map(corp_p, removePunctuation)
corp_p<-tm_map(corp_p, removeNumbers)
corp_p<-tm_map(corp_p, removeWords,stopwords("english"))
#stemming
corp_p<-tm_map(corp,stemDocument)
inspect(tdm_p)
tdm_p<-TermDocumentMatrix(corp_p)
tdm_p
inspect(tdm_p)
tdm_p$dimnames$Terms
View(tdm_p$dimnames$Terms)
complete_analysis<-function(y){
#creating the corpus
library(tm)
corp_y<-Corpus(VectorSource(y))
#tokenization
corp_y<-tm_map(corp,stripWhitespace)
corp_y<-tm_map(corp, removePunctuation)
corp_y<-tm_map(corp, removeNumbers)
#stopwords
corp_y<-tm_map(corp, removeWords,stopwords("SMART"))
#stemming
corp_y<-tm_map(corp,stemDocument)
#TF-IDF and latent semantic analysis
tdm<-TermDocumentMatrix(corp_y)
tfidf<-weightTfIdf(tdm)}
complete_analysis(corp_c)
complete_analysis<-function(y){
#creating the corpus
library(tm)
corp_y<-Corpus(VectorSource(y))
#tokenization
corp_y<-tm_map(corp,stripWhitespace)
corp_y<-tm_map(corp, removePunctuation)
corp_y<-tm_map(corp, removeNumbers)
#stopwords
corp_y<-tm_map(corp, removeWords,stopwords("SMART"))
#stemming
corp_y<-tm_map(corp,stemDocument)
#TF-IDF and latent semantic analysis
tdm_y<-TermDocumentMatrix(corp_y)
tfidf_Y<-weightTfIdf(tdm)}
complete_analysis(corp_c)
View(tdm_c$dimnames$Terms)
## Loading and cleaning the data
#x <- readLines("netflix.csv")
data<- read.csv("netflix.csv", header =TRUE, sep=";")
#Separating text variables to other variables
cons<-data$cons
pros<-data$pros
#Converting foreign characters into english
library(gsubfn)
cons<-gsub("Ç","c",cons)
cons<-gsub("¸",",",cons)
cons<-gsub("ƒ","f",cons)
cons<-gsub("ÿ","y",cons)
cons<-gsub("¶","",cons)
cons<-gsub("½","",cons)
pros<-gsub("Ç","c",pros)
pros<-gsub("¸",",",pros)
pros<-gsub("ƒ","f",pros)
pros<-gsub("ÿ","y",pros)
pros<-gsub("¶","",pros)
pros<-gsub("½","",pros)
pros<-pros[-c(809,810)]
cons<-cons[-c(809,810)]
library(tm)
corp_p<-Corpus(VectorSource(pros))
corp_c<-Corpus(VectorSource(cons))
corp_p<-tm_map(corp_p, stripWhitespace)
corp_p<-tm_map(corp_p, removePunctuation)
corp_p<-tm_map(corp_p, removeNumbers)
corp_p<-tm_map(corp_p, removeWords,stopwords("english"))
#stemming
corp_p<-tm_map(corp,stemDocument)
tdm_p<-TermDocumentMatrix(corp_p)
View(tdm_p$dimnames$Terms)
View(corp_p)
inspect(corp_p)
corp_p<-tm_map(corp_p, stripWhitespace)
corp_p<-tm_map(corp_p, removePunctuation)
corp_p<-tm_map(corp_p, removeNumbers)
corp_p<-tm_map(corp_p, removeWords,stopwords("english"))
#stemming
corp_p<-tm_map(corp,stemDocument)
#stemming
corp_p<-tm_map(corp_p,stemDocument)
tdm_p<-TermDocumentMatrix(corp_p)
inspect(corp_p)
corp_p<-Corpus(VectorSource(pros))
corp_p<-tm_map(corp_p, stripWhitespace)
corp_p<-tm_map(corp_p, removePunctuation)
corp_p<-tm_map(corp_p, removeNumbers)
corp_p<-tm_map(corp_p, removeWords,stopwords("english"))
#stemming
corp_p<-tm_map(corp_p,stemDocument)
inspect(corp_p)
inspect(corp_c)
corp_c<-Corpus(VectorSource(cons))
corp_p<-tm_map(corp_p, stripWhitespace)
corp_p<-tm_map(corp_p, removePunctuation)
corp_p<-tm_map(corp_p, removeNumbers)
corp_c<-tm_map(corp_c, stripWhitespace)
corp_c<-tm_map(corp_c, removePunctuation)
corp_c<-tm_map(corp_c, removeNumbers)
#removing stopwords
corp_p<-tm_map(corp_p, removeWords,stopwords("english"))
corp_c<-tm_map(corp_c, removeWords,stopwords("english"))
#stemming the corpuses
corp_p<-tm_map(corp_p,stemDocument)
corp_c<-tm_map(corp_c,stemDocument)
View(corp_c)
inspect(corp_c)
inspect(corp_p)
#creating TermDocumentMatrix
tdm_p<-TermDocumentMatrix(corp_p)
tdm_c<-TermDocumentMatrix(corp_c)
#modifing words to differentiate between positive and negative terms.
tdm_p$dimnames$Terms <- paste0("P_",tdm$dimnames$Terms)
#modifing words to differentiate between positive and negative terms.
tdm_p$dimnames$Terms <- paste0("P_",tdm_p$dimnames$Terms)
tdm_p$dimnames$Terms
tfidf_p<-weightTfIdf(tdm_p)
inspect(tfidf_p)
inspect(tfidf_p$dimnames)
inspect(tfidf_p$dimnames$Terms)
tfidf_c<-weightTfIdf(tdm_c)
tdm_c$dimnames$Terms <- paste0("C_",tdm_p$dimnames$Terms)
tfidf_c<-weightTfIdf(tdm_c)
tfidf_c<-weightTfIdf(tdm_c)
tdm_c<-TermDocumentMatrix(corp_c)
tdm_c$dimnames$Terms <- paste0("C_",tdm_p$dimnames$Terms)
tfidf_c<-weightTfIdf(tdm_c)
View(tfidf_p$nrow)
#creating TermDocumentMatrix
tdm_p<-TermDocumentMatrix(corp_p)
tfidf_pp<-weightTfIdf(tdm_p)
inspect(tfidf_pp)
tdm_c<-TermDocumentMatrix(corp_c)
tfidf_c<-weightTfIdf(tdm_c)
tdm_c$dimnames$Terms <- paste0("C_",tdm_p$dimnames$Terms)
tfidf_c<-weightTfIdf(tdm_c)
View(tdm_c)
View(tdm_p)
tdm_c<-TermDocumentMatrix(corp_c)
tdm_c$dimnames$Terms <- paste0("C_",tdm_c$dimnames$Terms)
tfidf_c<-weightTfIdf(tdm_c)
inspect(tfidf_c)
tfidf_df<-data.frame(tfidf_c)
tfidf_c_df<-data.frame(tfidf_c$dimnames$Terms,tfidf_c$dimnames$Docs)
library(lsa)
lsa.tfidf_c<-lsa(tfidf_c,dim=20)
words.df<-as.data.frame(as.matrix(lsa.tfidf_c$dk))
View(words.df)
tdm_pp<-TermDocumentMatrix(corp_p)
words.df_c<-as.data.frame(as.matrix(lsa.tfidf_c$dk))
View(words.df_c)
words.df==words.df_c
words.df=words.df_c
words.df_c<-as.data.frame(as.matrix(lsa.tfidf_c$dk))
tdm_c<-TermDocumentMatrix(corp_c)
tdm_cc<-TermDocumentMatrix(corp_c)
tfidf_cc<-weightTfIdf(tdm_cc)
lsa.tfidf_cc<-lsa(tfidf_cc,dim=20)
words.df_cc<-as.data.frame(as.matrix(lsa.tfidf_cc$dk))
View(words.df_cc)
words.df_c==words.df_cc
#creating TermDocumentMatrix
tdm_p<-TermDocumentMatrix(corp_p)
tdm_c<-TermDocumentMatrix(corp_c)
#modifing words to differentiate between positive and negative terms.
tdm_p$dimnames$Terms <- paste0("P_",tdm_p$dimnames$Terms)
tdm_c$dimnames$Terms <- paste0("C_",tdm_c$dimnames$Terms)
#TF-IDF
tfidf_c<-weightTfIdf(tdm_c)
tfidf_p<-weightTfIdf(tdm_p)
lsa.tfidf_p<-lsa(tfidf_p,dim=20)
words.df_p<-as.data.frame(as.matrix(lsa.tfidf_p$dk))
cons_new<- str_replace_all(cons, "(\\b\\w)", 'C_\\1')
install.packages("regrex")
install.packages("regex")
install.packages("Regex")
install.package("regex")
install.packages(regex)
install.packages("regex")
install.packages("Regex")
install.packages("stringr")
install.packages("stringr")
install.packages("stringr")
cons_new<- str_replace_all(cons, "(\\b\\w)", 'C_\\1')
library(stringr)
cons_new<- str_replace_all(cons, "(\\b\\w)", 'C_\\1')
View(cons_new)
corp
View(corp_c$dmeta)
View(corp_c$content)
corp_c$content<- str_replace_all(corp_c$content, "(\\b\\w)", 'C_\\1')
View(corp_c$content)
corp_p$content<- str_replace_all(corp_p$content, "(\\b\\w)", 'p_\\1')
corp<-corp_c
corp$content<-paste(corp_c$content,corp_p$content)
corp$content
View(corp$content)
corp_p$content<- str_replace_all(corp_p$content, "(\\b\\w)", 'P_\\1')
corp$content<-paste(corp_c$content,corp_p$content)
View(corp$content)
tdm<-TermDocumentMatrix(corp)
library(tm)
tdm<-TermDocumentMatrix(corp)
tdidf<- weightTfIdf(tdm)
tfidf<- weightTfIdf(tdm)
library(lsa)
lsa.tfidf<-lsa(tfidf,dim=20)
words.df<-as.data.frame(as.matrix(lsa.tfidf$dk))
View(words.df)
#Implementing the logistic regression model
#aggiungo una colonna e rendo binaria la variabile overall rating
data$over.b<-0
data$over.b<-ifelse(data$overall.ratings>3.5,1,0)
summary(data$over.b)
inspect(tfidf)
#Converting foreign characters into english and dropping french rows
library(gsubfn)
#creating Corpus
library(tm)
inspect(tfidf)
inspect(tfidf$dimnames$Terms)
View(tfidf$dimnames$Terms)
corp_p
inspect(corp_p)
corp_p$content<- str_replace_all(corp_p$content, "p_", "")
library(readr)
corp_p$content<- str_replace_all(corp_p$content, "p_", "")
library(stringr)
corp_p$content<- str_replace_all(corp_p$content, "p_", "")
View(corp_p$content)
#Viewing complete dataset
View(data)
corp$content<-paste(corp_c$content,corp_p$content)
View(corp$content)
tdm<-TermDocumentMatrix(corp)
tfidf<- weightTfIdf(tdm)
View(tfidf$dimnames$Terms)
library(lsa)
lsa.tfidf<-lsa(tfidf,dim=20)
words.df<-as.data.frame(as.matrix(lsa.tfidf$dk))
summary(data$over.b)
View(corp$content)
View(words.df)
#Viewing complete dataset
View(data)
#str(data)
data<-data[-c(809,810)]
View(data)
#str(data)
data<-data[-c(809,810),]
#sample 60% training data
training<-sample(c(1:810), 0.6*810)
training
#run logistic model on training
trainData = cbind(label=data$over.b[training],words.df[training,])
reg<-glm(label ~.,data=trainData, family='binomial')
summary(reg)
#compute accuracy on validation set
ValidData<-cbind(label=data$over.b[-training],words.df[-training,])
pred<-predict(reg,newdata=ValidData,type='response')
#confusion matrix
library(caret)
pred
ValidData
pred_factor <- factor(ifelse(pred>0.5,1,0), levels = 1:323)
pred_vector<-as.vector(pred_factor)
pred_vector[is.na(pred_vector)] <- 0
pred_factor<-as.factor(pred_vector)
over.b_factor<-factor(data$over.b[-training], levels = 1:324)
over.b_vector<-as.vector(over.b_factor)
over.b_vector[is.na(over.b_vector)] <- 0
over.b_factor<-as.factor(over.b_vector)
confusionMatrix(pred_factor, over.b_factor)
#creating lift chart
#install.packages("gains")
library(gains)
pred_num<-as.numeric(pred)
over.b_num<- as.numeric(as.character(over.b_factor))
gain<-gains(over.b_num,pred_num, groups=10)
barplot(gain$mean.resp/mean(over.b_num), names.arg = gain$depth, xlab="Percentile", ylab= "Mean Response", main="Decile-wise lift chart")
##Correct K-Fold with right measure
library(caret)
library(MLmetrics)
#Creating dataset for K-fold and making adjustments for training the model
K_Fold_Data<-cbind(output=data$over.b,words.df)
View(K_Fold_Data)
K_Fold_Data$output<-as.factor(K_Fold_Data$output)
K_Fold_Data$output<-make.names(K_Fold_Data$output)
#Creating the list for the output metrix
MySummary  <- function(data, lev = NULL, model = NULL){
a1 <- defaultSummary(data, lev, model)
b1 <- twoClassSummary(data, lev, model)
c1 <- prSummary(data, lev, model)
out <- c(a1, b1, c1)
out}
#Implementing CV
ctrl <- trainControl(method = "cv",number = 10,savePredictions = TRUE, summaryFunction = MySummary,classProbs = TRUE)
#traing the model and looking at the results.
mod_fit <- train(output~.,data =K_Fold_Data,method = "glm",trControl = ctrl)
mod_fit$results
tfidf_2<-tfidf
k-fold_LSA<-function(x,y){
lsa.x<-lsa(tfidf,dim=y)
}
k-fold_LSA<-function(x,y){
lsa.x<-lsa(tfidf_2,dim=y)
}
kfold_LSA<-function(x,y){
lsa.x<-lsa(tfidf_2,dim=y)
}
kfold_LSA<-function(y){
lsa.y<-lsa(tfidf_2,dim=y)
}
kfold_LSA(5)
lsa_5<-kfold_LSA(5)
words.df_5<-as.data.frame(as.matrix(lsa_5$dk))
View(words.df_5)
kfold_LSA<-function(y){
lsa<-lsa(tfidf_2,dim=y)
words.df_5<-as.data.frame(as.matrix(lsa$dk))
K_Fold_Data<-cbind(output=data$over.b,words.df)
K_Fold_Data$output<-as.factor(K_Fold_Data$output)
K_Fold_Data$output<-make.names(K_Fold_Data$output)
#traing the model and looking at the results.
mod_fit <- train(output~.,data =K_Fold_Data,method = "glm",trControl = ctrl)
print(mod_fit$results)
}
kfold_LSA(5)
View(mod_fit$results)
Lsa_results_vector<-1:20
View(mod_fit$results)
mod_fit$results[0]
View(mod_fit$results[0])
mod_fit$results[0,]
mod_fit$results[1,]
DF <- data.frame(num=rep(NA, 22), txt=rep("", N),stringsAsFactors=FALSE)
DF <- data.frame(num=rep(NA, 22), txt=rep("", 22),stringsAsFactors=FALSE)
View(DF)
df<-NULL
df
Kfold_6<-kfold_LSA(6)
df[6,]<-Kfold_i$results[1,]
df[6,]<-Kfold_6$results[1,]
View(df)
df<-data.frame()
df[6,]<-Kfold_6$results[1,]
View(df)
mod_fit$metric
mod_fit$metric[0,]
rbind(mod_fit$metric,0)
ls(mod_fit)
ls(mod_fit$results)
df<-data.frame( "Accuracy","AccuracySD","AUC")
View(df)
df<-data.frame( "Accuracy","AccuracySD","AUC")
View(df)
df<-data.frame(matrix(nrow=22 ncol=20))
df<-data.frame(matrix(nrow=22 ncol=20))
df<-data.frame(matrix(nrow=22, ncol=20))
df
Kfold_6<-kfold_LSA(6)
df[6,]<-Kfold_6$results[1,]
View(df)
df[6,]<-Kfold_6$results[1,]
rbind(df,6)<-Kfold_6$results[1,]
require(rbind)
rbind(df,6)<-Kfold_6$results[1,]
install.packages("plyr")
install.packages("plyr")
rbind(df,6)<-Kfold_6$results[1,]
library(plyr)
K_fold_6<-Kfold_6$results[1,]
K_fold_6
K_fold_6<-Kfold_6$results[1,]
K_fold_6
Kfold_6$results[1,]
Kfold_6$results[1,3]
Kfold_6$results
Kfold_6<-kfold_LSA(6)
kfold_LSA<-function(y){
lsa<-lsa(tfidf_2,dim=y)
words.df_5<-as.data.frame(as.matrix(lsa$dk))
K_Fold_Data<-cbind(output=data$over.b,words.df)
K_Fold_Data$output<-as.factor(K_Fold_Data$output)
K_Fold_Data$output<-make.names(K_Fold_Data$output)
#traing the model and looking at the results.
mod_fit <- train(output~.,data =K_Fold_Data,method = "glm",trControl = ctrl)
print(mod_fit$results)
}
Kfold_6<-kfold_LSA(6)
library(lsa)
Kfold_6<-kfold_LSA(6)
kfold_LSA<-function(y){
lsa<-lsa(tfidf_2,dim=y)
words.df_5<-as.data.frame(as.matrix(lsa$dk))
K_Fold_Data<-cbind(output=data$over.b,words.df)
K_Fold_Data$output<-as.factor(K_Fold_Data$output)
K_Fold_Data$output<-make.names(K_Fold_Data$output)
#traing the model and looking at the results.
mod_fit <- train(output~.,data =K_Fold_Data,method = "glm",trControl = ctrl)
print(mod_fit$results)
}
Kfold_6<-kfold_LSA(6)
kfold_LSA(5)
library(lsa)
kfold_LSA<-function(y){
lsa<-lsa(tfidf_2,dim=y)
words.df_5<-as.data.frame(as.matrix(lsa$dk))
K_Fold_Data<-cbind(output=data$over.b,words.df)
K_Fold_Data$output<-as.factor(K_Fold_Data$output)
K_Fold_Data$output<-make.names(K_Fold_Data$output)
#traing the model and looking at the results.
mod_fit <- train(output~.,data =K_Fold_Data,method = "glm",trControl = ctrl)
print(mod_fit$results)
}
Kfold_6<-kfold_LSA(6)
Kfold_6<-kfold_LSA(6)
kfold_LSA<-function(y){
lsa<-lsa(tfidf_2,dim=y)
words.df_5<-as.data.frame(as.matrix(lsa$dk))
K_Fold_Data<-cbind(output=data$over.b,words.df)
K_Fold_Data$output<-as.factor(K_Fold_Data$output)
K_Fold_Data$output<-make.names(K_Fold_Data$output)
#traing the model and looking at the results.
mod_fit <- train(output~.,data =K_Fold_Data,method = "glm",trControl = ctrl)
print(mod_fit$results)
}
Kfold_6<-kfold_LSA(6)
#creating Corpus
library(tm)
Kfold_6<-kfold_LSA(6)
#confusion matrix
library(caret)
Kfold_6<-kfold_LSA(6)
Kfold_6
View(Kfold_6)
df[6]<-Kfold_6
View(df)
df[6,]<-Kfold_6
df<-data.frame(matrix(nrow=22, ncol=20))
K_fold_df<-
for(i in 1:20){
Kfold_i<-kfold_LSA(i)
df[i,]<-Kfold_i
View(df)
}
View(df)
colnames(mod_fit$results)
names(df)
names(df)<-colnames(mod_fit$results)
lsa.tfidf_3<-lsa(tfidf,dim=1)
words.df_c<-as.data.frame(as.matrix(lsa.tfidf_c$dk))
words.df_p<-as.data.frame(as.matrix(lsa.tfidf_p$dk))
words.df_3<-as.data.frame(as.matrix(lsa.tfidf_3$dk))
View(words.df_3)
lsa.tfidf_3<-lsa(tfidf,dim=0)
words.df_3<-as.data.frame(as.matrix(lsa.tfidf_3$dk))
View(words.df_3)
lsa.tfidf_4<-lsa(tfidf,dim=5)
words.df_4<-as.data.frame(as.matrix(lsa.tfidf_4$dk))
View(words.df_4)
View(words.df)
View(words.df_4)
View(K_Fold_Data)
mod_fit_2<- train(output~V1,data =K_Fold_Data,method = "glm",trControl = ctrl)
mod_fit_2$results
mod_fit_2<- train(output~c(V1,V2),data =K_Fold_Data,method = "glm",trControl = ctrl)
mod_fit_2<- train(output~V1+V2,data =K_Fold_Data,method = "glm",trControl = ctrl)
mod_fit_2$results
mod_fit_2<- train(output~V1+V2+V3,data =K_Fold_Data,method = "glm",trControl = ctrl)
mod_fit_2$results
mod_fit_2<- train(output~.,data =K_Fold_Data,method = "glm",trControl = ctrl)
mod_fit_2$results
mod_fit_2<- train(output~V1+V2+V3+V4+V5+V6+V7,data =K_Fold_Data,method = "glm",trControl = ctrl)
mod_fit_2$results
mod_fit_2<- train(output~V1+V2+V3+V4+V5,data =K_Fold_Data,method = "glm",trControl = ctrl)
mod_fit_2$results
mod_fit_2<- train(output~V1+V2+V3,data =K_Fold_Data,method = "glm",trControl = ctrl)
mod_fit_2$results
mod_fit_2<- train(output~V1+V2+V3+V4,data =K_Fold_Data,method = "glm",trControl = ctrl)
mod_fit_2$results
