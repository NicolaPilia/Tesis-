library(tm)
corp<-Corpus(VectorSource(y))
#tokenization
corp<-tm_map(corp,stripWhitespace)
corp<-tm_map(corp, removePunctuation)
corp<-tm_map(corp, removeNumbers)
#stopwords
corp<-tm_map(corp, removeWords,stopwords("SMART"))
#stemming
corp<-tm_map(corp,stemDocument)
#TF-IDF and latent semantic analysis
tdm<-TermDocumentMatrix(corp)
tfidf<-weightTfIdf(tdm)
library(lsa)
lsa.tfidf<-lsa(tfidf,dim=z)
words.df<-as.data.frame(as.matrix(lsa.tfidf$dk))
}
View(complete_analysis)
cons<-complete_analysis(data,cons,20)
complete_analysis<-function(df=x,variable=y,dim_LSA=z){
y<-x[y]
#creating the corpus
library(tm)
corp<-Corpus(VectorSource(y))
#tokenization
corp<-tm_map(corp,stripWhitespace)
corp<-tm_map(corp, removePunctuation)
corp<-tm_map(corp, removeNumbers)
#stopwords
corp<-tm_map(corp, removeWords,stopwords("SMART"))
#stemming
corp<-tm_map(corp,stemDocument)
#TF-IDF and latent semantic analysis
tdm<-TermDocumentMatrix(corp)
tfidf<-weightTfIdf(tdm)
library(lsa)
lsa.tfidf<-lsa(tfidf,dim=z)
words.df<-as.data.frame(as.matrix(lsa.tfidf$dk))
}
cons<-complete_analysis(data,cons,20)
#Viewing complete dataset
View(data)
data<- read.csv("netflix.csv", header =TRUE, sep=";")
#Viewing complete dataset
View(data)
cons<-complete_analysis(data,cons,20)
#Viewing complete dataset
View(data)
cons<-complete_analysis(data,"cons",20)
cons<-complete_analysis(data,cons,20)
cons<-complete_analysis(data,data$cons,20)
cons<-complete_analysis(data,cons,20)
traceback()
complete_analysis()
data$cons
cons<-complete_analysis(df=data,variable=cons,dim_LSA=20)
cons<-data$cons
complete_analysis<-function(y,dim_LSA=z){
#creating the corpus
library(tm)
corp<-Corpus(VectorSource(y))
#tokenization
corp<-tm_map(corp,stripWhitespace)
corp<-tm_map(corp, removePunctuation)
corp<-tm_map(corp, removeNumbers)
#stopwords
corp<-tm_map(corp, removeWords,stopwords("SMART"))
#stemming
corp<-tm_map(corp,stemDocument)
#TF-IDF and latent semantic analysis
tdm<-TermDocumentMatrix(corp)
tfidf<-weightTfIdf(tdm)
library(lsa)
lsa.tfidf<-lsa(tfidf,dim=z)
words.df<-as.data.frame(as.matrix(lsa.tfidf$dk))
}
complete_analysis(cons,dim_LSA=20)
traceback()
complete_analysis(cons,20)
traceback()
complete_analysis<-function(y){
#creating the corpus
library(tm)
corp<-Corpus(VectorSource(y))
#tokenization
corp<-tm_map(corp,stripWhitespace)
corp<-tm_map(corp, removePunctuation)
corp<-tm_map(corp, removeNumbers)
#stopwords
corp<-tm_map(corp, removeWords,stopwords("SMART"))
#stemming
corp<-tm_map(corp,stemDocument)
#TF-IDF and latent semantic analysis
tdm<-TermDocumentMatrix(corp)
tfidf<-weightTfIdf(tdm)
library(lsa)
lsa.tfidf<-lsa(tfidf,dim=20)
words.df<-as.data.frame(as.matrix(lsa.tfidf$dk))
}
complete_analysis(cons)
cons<-complete_analysis(cons)
inspect(cons)
View(cons)
pros<-data$pros
corp<-Corpus(VectorSource(pros))
#tokenization
corp<-tm_map(corp,stripWhitespace)
corp<-tm_map(corp, removePunctuation)
corp<-tm_map(corp, removeNumbers)
corp<-tm_map(corp, removeWords,stopwords("SMART"))
#stemming
corp<-tm_map(corp,stemDocument)
#TF-IDF and latent semantic analysis
tdm<-TermDocumentMatrix(corp)
tfidf<-weightTfIdf(tdm)
lsa.tfidf<-lsa(tfidf,dim=20)
words.df<-as.data.frame(as.matrix(lsa.tfidf$dk))
View(words.df)
rm(pros)
pros<-data$pros
complete_analysis(pros)
pros2<-complete_analysis(pros)
View(pros2)
words.df==pros2
complete_analysis<-function(y,z){
#creating the corpus
library(tm)
corp<-Corpus(VectorSource(y))
#tokenization
corp<-tm_map(corp,stripWhitespace)
corp<-tm_map(corp, removePunctuation)
corp<-tm_map(corp, removeNumbers)
#stopwords
corp<-tm_map(corp, removeWords,stopwords("SMART"))
#stemming
corp<-tm_map(corp,stemDocument)
#TF-IDF and latent semantic analysis
tdm<-TermDocumentMatrix(corp)
tfidf<-weightTfIdf(tdm)
library(lsa)
lsa.tfidf<-lsa(tfidf,dim=z)
words.df<-as.data.frame(as.matrix(lsa.tfidf$dk))
}
cons<-complete_analysis(cons,20)
cons<-complete_analysis(cons,20)
d<-10
lsa.tfidf<-lsa(tfidf,dim=d)
View(lsa.tfidf)
View(lsa.tfidf)
complete_analysis<-function(y,z){
#creating the corpus
library(tm)
corp<-Corpus(VectorSource(y))
#tokenization
corp<-tm_map(corp,stripWhitespace)
corp<-tm_map(corp, removePunctuation)
corp<-tm_map(corp, removeNumbers)
#stopwords
corp<-tm_map(corp, removeWords,stopwords("SMART"))
#stemming
corp<-tm_map(corp,stemDocument)
#TF-IDF and latent semantic analysis
tdm<-TermDocumentMatrix(corp)
tfidf<-weightTfIdf(tdm)
library(lsa)
z<-z
lsa.tfidf<-lsa(tfidf,dim=z)
words.df<-as.data.frame(as.matrix(lsa.tfidf$dk))
}
cons<-complete_analysis(cons,20)
cons2<-complete_analysis(cons,20)
cons2<-complete_analysis(cons,20)
z<-integer(20)
complete_analysis<-function(y,z){
#creating the corpus
library(tm)
corp<-Corpus(VectorSource(y))
#tokenization
corp<-tm_map(corp,stripWhitespace)
corp<-tm_map(corp, removePunctuation)
corp<-tm_map(corp, removeNumbers)
#stopwords
corp<-tm_map(corp, removeWords,stopwords("SMART"))
#stemming
corp<-tm_map(corp,stemDocument)
#TF-IDF and latent semantic analysis
tdm<-TermDocumentMatrix(corp)
tfidf<-weightTfIdf(tdm)
library(lsa)
z<-integer(z)
lsa.tfidf<-lsa(tfidf,dim=z)
words.df<-as.data.frame(as.matrix(lsa.tfidf$dk))
}
cons2<-complete_analysis(cons,20)
cons2<-complete_analysis(cons,20)
z<-20
complete_analysis<-function(y,z){
#creating the corpus
library(tm)
corp<-Corpus(VectorSource(y))
#tokenization
corp<-tm_map(corp,stripWhitespace)
corp<-tm_map(corp, removePunctuation)
corp<-tm_map(corp, removeNumbers)
#stopwords
corp<-tm_map(corp, removeWords,stopwords("SMART"))
#stemming
corp<-tm_map(corp,stemDocument)
#TF-IDF and latent semantic analysis
tdm<-TermDocumentMatrix(corp)
tfidf<-weightTfIdf(tdm)
library(lsa)
z<-z
lsa.tfidf<-lsa(tfidf,dim=z)
words.df<-as.data.frame(as.matrix(lsa.tfidf$dk))
}
cons2<-complete_analysis(cons,20)
omplete_analysis<-function(y,ciao){
#creating the corpus
library(tm)
corp<-Corpus(VectorSource(y))
#tokenization
corp<-tm_map(corp,stripWhitespace)
corp<-tm_map(corp, removePunctuation)
corp<-tm_map(corp, removeNumbers)
#stopwords
corp<-tm_map(corp, removeWords,stopwords("SMART"))
#stemming
corp<-tm_map(corp,stemDocument)
#TF-IDF and latent semantic analysis
tdm<-TermDocumentMatrix(corp)
tfidf<-weightTfIdf(tdm)
library(lsa)
lsa.tfidf<-lsa(tfidf,dim=ciao)
words.df<-as.data.frame(as.matrix(lsa.tfidf$dk))
}
cons2<-complete_analysis(cons,20)
#produce confusion matrix
library(caret)
confusionMatrix(pred_factor, over.b_factor)
View(words.df)
#aggiungo una colonna e rendo binaria la variabile overall rating
data$over.b<-0
data$over.b<-ifelse(data$overall.ratings>2.5,1,0)
#sample 60% training data
training<-sample(c(1:810), 0.6*810)
#run logistic model on training
trainData = cbind(label=data$over.b[training],words.df[training,])
reg<-glm(label ~.,data=trainData, family='binomial')
summary(reg)
#compute accuracy on validation set
ValidData<-cbind(label=data$over.b[-training],words.df[-training,])
pred<-predict(reg,newdata=ValidData,type='response')
confusionMatrix(ifelse(pred>0.5,1,0), data$over.b[-training])
over.B<-conf_clean(over.B)
over.b_factor<-factor(data$over.b[-training], levels = 1:324)
over.b_vector<-as.vector(over.b_factor)
over.b_vector[is.na(over.b_vector)] <- 0
over.b_factor<-as.factor(over.b_vector)
pred_factor <- factor(ifelse(pred>0.5,1,0), levels = 1:324))
pred_factor <- factor(ifelse(pred>0.5,1,0), levels = 1:324)
pred_vector<-as.vector(pred_factor)
pred_vector[is.na(pred_vector)] <- 0
pred_factor<-as.factor(pred_vector)
confusionMatrix(pred_factor, over.b_factor)
#creating lift chart
gain<-gains(over.b_factor,pred_factor)
#creating lift chart
library(gains)
#creating lift chart
install.packages("gains")
gain<-gains(over.b_factor,pred_factor)
library(gains)
gain<-gains(over.b_factor,pred_factor)
over.b_factor
pred_factor
is.numeric(pred_factor)
pred_num<-numeric(pred_factor)
pred_num<-as.numeric(pred_factor)
over.b_num<- as.numeric(over.b_factor)
gain<-gains(over.b_factor,pred_factor)
gain<-gains(over.b_num,pred_num)
pred
barplot(gain$mean.resp/mean(over.b_num), nnames.arg = gain$depth, xlab="Percentile", ylab= "Mean Response", main="Decile-wise lift chart")
barplot(gain$mean.resp/mean(over.b_num), names.arg = gain$depth, xlab="Percentile", ylab= "Mean Response", main="Decile-wise lift chart")
gain<-gains(over.b_num,pred_num)
barplot(gain$mean.resp/mean(over.b_num), names.arg = gain$depth, xlab="Percentile", ylab= "Mean Response", main="Decile-wise lift chart")
j
barplot(gain$mean.resp/mean(over.b_num), names.arg = gain$depth, xlab="Percentile", ylab= "Mean Response", main="Decile-wise lift chart")
barplot(gain$mean.resp/mean(over.b_num), names.arg = gain$depth, xlab="Percentile", ylab= "Mean Response", main="Decile-wise lift chart")
mean(over.b_num)
over.b_num
over.b_factor
pred_num<-as.numeric(as.character(pred_factor)
over.b_num<- as.numeric(as.character(over.b_factor)
pred_num<-as.numeric(as.character(pred_factor))
over.b_num<- as.numeric(as.character(over.b_factor))
gain<-gains(over.b_num,pred_num)
barplot(gain$mean.resp/mean(over.b_num), names.arg = gain$depth, xlab="Percentile", ylab= "Mean Response", main="Decile-wise lift chart")
gain
gain<-gains(over.b_num,pred_num, groups=10)
gain
over.b_num
pred_num
pred_factor
library(caret)
gain<-gains(over.b_num,pred_num, groups=dim(over.b_num))
library(gains)
gain<-gains(over.b_num,pred_num, groups=dim(over.b_num))
gain<-gains(over.b_num,pred_num, groups=dim(over.b_factor))
gain<-gains(over.b_num,pred_num, groups=10)
dim(over.b_factor)
dim(over.b_num)
dim(over.b_vector)
barplot(gain$mean.resp/mean(over.b_num), names.arg = gain$depth, xlab="Percentile", ylab= "Mean Response", main="Decile-wise lift chart")
Lift_chart_df<-data.frame(over.b_num,pred_num)
View(Lift_chart_df)
View(ValidData)
View(Lift_chart_df)
Lift_chart_df<-data.frame(over.b_factor,pred_factor)
View(Lift_chart_df)
pred_factor
Lift_chart_df$pred_factor
pred_factor==Lift_chart_df$pred_factor
over.b_num==Lift_chart_df$over.b_factor
over.b_factor==Lift_chart_df$over.b_factor
gain<-gains(Lift_chart_df$over.b_factor,Lift_chart_df$pred_factor, groups=10)
Lift_chart_df<-data.frame(over.b_num,pred_num)
gain<-gains(Lift_chart_df$over.b_factor,Lift_chart_df$pred_factor, groups=10)
gain<-gains(Lift_chart_df$over.b_num,Lift_chart_df$pred_num, groups=10)
barplot(gain$mean.resp/mean(over.b_num), names.arg = gain$depth, xlab="Percentile", ylab= "Mean Response", main="Decile-wise lift chart")
pred
pred_num
pred_num<-as.numeric(pred)
gain<-gains(over.b_num,pred_num, groups=10)
barplot(gain$mean.resp/mean(over.b_num), names.arg = gain$depth, xlab="Percentile", ylab= "Mean Response", main="Decile-wise lift chart")
pred_num
pred_num==pred
confusionMatrix(pred_factor, over.b_factor)
View(data)
is.na(data$advice.to.mgmt)
data$advice.to.mgmt==""
sum(data$advice.to.mgmt=="")
251/810
sum(data$advice.to.mgmt=="")/sum(data$advice.to.mgmt)
sum(data$advice.to.mgmt=="")/nrow(data)
install.packages("shiny")
library(shiny)
runGist("5846650")
library(shiny)
runGist("5846650")
confusionMatrix(pred_factor, over.b_factor)
#confusion matrix
library(caret)
confusionMatrix(pred_factor, over.b_factor)
#K-fold
library(boot)
rep(0,10)
require(caret)
flds <- createFolds(data$over.b, k = 10, list = TRUE, returnTrain = FALSE)
View(flds)
names(flds)[1] <- "train"
flds$train
flds
names(flds)[1] <- "Fold01"
flds
training
library(caret)
names(getModelInfo(train()))
K_Fold_Data<-cbind(label=data$over.b,words.df)
View(K_Fold_Data)
K_Fold_Data<-cbind(output=data$over.b,words.df)
model<-train(output~.,data=K_Fold_Data,method="glm",trControl=trainControl(method = "cv", number = 10,verboseIter = TRUE))
class(K_Fold_Data[output])
View(K_Fold_Data)
class(K_Fold_Data[output])
K_Fold_Data[output]
K_Fold_Data[output]
K_Fold_Data[output]
K_Fold_Data$output
class(K_Fold_Data$output)
K_Fold_Data$output<-as.factor(K_Fold_Data$output)
class(K_Fold_Data$output)
model<-train(output~.,data=K_Fold_Data,method="glm",trControl=trainControl(method = "cv", number = 10,verboseIter = TRUE))
View(model)
model
model<-train(output~.,data=K_Fold_Data,method="glm",trControl=trainControl(method = "cv", number = 10,verboseIter = TRUE), metric="ROC")
model<-train(output~.,data=K_Fold_Data,method="glm",trControl=trainControl(method = "cv", number = 10,verboseIter = TRUE), metric="ROC", classProbs=TRUE)
model<-train(output~.,data=K_Fold_Data,method="glm",trControl=trainControl(method = "cv", number = 10,verboseIter = TRUE, classProbs = TRUE), metric="ROC")
class(K_Fold_Data$output)
K_Fold_Data$output
model<-train(output~.,data=K_Fold_Data,method="glm",trControl=trainControl(method = "cv", number = 10,verboseIter = TRUE))
model
model<-train(output~.,data=K_Fold_Data,method="glm",trControl=trainControl(method = "cv", number = 10,verboseIter = TRUE),metric="Kappa")
model
model<-train(output~.,data=K_Fold_Data,method="glm",trControl=trainControl(method = "cv", number = 10,verboseIter = TRUE, classProbs = TRUE), metric="ROC")
levels(K_Fold_Data$output) <- c('POS', 'not-POS')
K_Fold_Data$output
levels(K_Fold_Data$output) <- c('not-POS', 'POS')
K_Fold_Data$output
class(K_Fold_Data$output)
model<-train(output~.,data=K_Fold_Data,method="glm",trControl=trainControl(method = "cv", number = 10,verboseIter = TRUE, classProbs = TRUE), metric="ROC")
?make.names
levels(K_Fold_Data$output) <- c('not.POS', 'POS')
model<-train(output~.,data=K_Fold_Data,method="glm",trControl=trainControl(method = "cv", number = 10,verboseIter = TRUE, classProbs = TRUE), metric="ROC")
model
levels(K_Fold_Data$output) <- c(0,1)
K_Fold_Data$output
MySummary  <- function(data, lev = NULL, model = NULL){
a1 <- defaultSummary(data, lev, model)
b1 <- twoClassSummary(data, lev, model)
c1 <- prSummary(data, lev, model)
out <- c(a1, b1, c1)
out}
ctrl <- trainControl(method = "cv",number = 10,savePredictions = TRUE, summaryFunction = MySummary,classProbs = TRUE)
require(caret)
ctrl <- trainControl(method = "cv",number = 10,savePredictions = TRUE, summaryFunction = MySummary,classProbs = TRUE)
mod_fit <- train(output~.,data =K_Fold_Data,method = "glm",trControl = ctrl)
make.names(K_Fold_Data)
K_Fold_Data
K_Fold_Data2<-make.names(K_Fold_Data)
mod_fit <- train(output~.,data =K_Fold_Data2,method = "glm",trControl = ctrl)
ctrl <- trainControl(method = "cv",number = 10,savePredictions = TRUE, summaryFunction = MySummary,classProbs = TRUE)
mod_fit <- train(output~.,data =K_Fold_Data2,method = "glm",trControl = ctrl)
K_Fold_Data2
K_Fold_Data2<-K_Fold_Data
K_Fold_Data2$output<-make.names(K_Fold_Data2$output)
K_Fold_Data2
mod_fit <- train(output~.,data =K_Fold_Data2,method = "glm",trControl = ctrl)
install.packages("MLmetrics")
mod_fit <- train(output~.,data =K_Fold_Data2,method = "glm",trControl = ctrl)
mod_fit
mod_fit$results
model<-train(output~.,data=K_Fold_Data,method="glm",trControl=trainControl(method = "cv", number = 10,verboseIter = TRUE, classProbs = TRUE), metric="ROC")
model<-train(output~.,data=K_Fold_Data2,method="glm",trControl=trainControl(method = "cv", number = 10,verboseIter = TRUE, classProbs = TRUE), metric="ROC")
levels(K_Fold_Data$output) <- c(0,1)
K_Fold_Data$output<-make.names(K_Fold_Data$output)
source('~/.active-rstudio-document', echo=TRUE)
mod_fit
mod_fit$metric
mod_fit$results
##Correct K-Fold with right measure
library(caret)
mod_fit$pred$obs
mod_fit$pred$R
for_lift <- data.frame(Class = model$pred$obs, rf = model$pred$R)
lift_obj <- lift(Class ~ rf, data = for_lift, class = "R")
for_lift <- data.frame(Class = mod_fit$pred$obs, rf = mod_fit$pred$R)
lift_obj <- lift(class ~ rf, data = for_lift, class = "R")
lift_obj <- lift(class ~ rf, data = for_lift, class = "R")
for_lift <- data.frame(predd = mod_fit$pred$obs, rf = mod_fit$pred$R)
lift_obj <- lift(predd ~ rf, data = for_lift, class = "R")
warnings(for_lift)
lift_obj <- lift(predd ~ rf, data = for_lift, class = "R")
mod_fit$pred$R
View(for_lift)
lift_obj <- lift(predd ~ rf, data = for_lift, class = "X1")
class(mod_fit$pred$R)
class(mod_fit$pred$obs)
as.factor(mod_fit$pred$R)
mod_fit$pred$R<-as.factor(mod_fit$pred$R)
lift_obj <- lift(predd ~ rf, data = for_lift, class = "X1")
View(for_lift)
library(ggplot2)
lift_obj <- lift(predd ~ rf, data = for_lift, class = "X1")
View(for_lift)
for_lift <- data.frame(predd = mod_fit$pred$obs, Log = mod_fit$pred$R)
lift_obj <- lift(predd ~ rf, data = for_lift, class = "X1")
lift_obj <- lift(predd ~ Log, data = for_lift, class = "X1")
warnings()
barplot(gain$mean.resp/mean(over.b_num), names.arg = gain$depth, xlab="Percentile", ylab= "Mean Response", main="Decile-wise lift chart")
confusionMatrix(pred_factor, over.b_factor)
#confusion matrix
library(caret)
confusionMatrix(pred_factor, over.b_factor)
Lift_chart_df<-data.frame(over.b_num,pred)
Lift_chart_df
barplot(gain$mean.resp/mean(over.b_num), names.arg = gain$depth, xlab="Percentile", ylab= "Mean Response", main="Decile-wise lift chart")
#traing the model and looking at the results.
mod_fit <- train(output~.,data =K_Fold_Data2,method = "glm",trControl = ctrl)
mod_fit$results
confusionMatrix(pred_factor, over.b_factor)
library(tm)
#Converting foreign characters into english
library(gsubfn)
library(lsa)
#creating the corpus
library(tm)
library(gains)
#confusion matrix
library(caret)
mod_fit$results
##Correct K-Fold with right measure
library(caret)
library(MLmetrics)
#creating the corpus
library(tm)
#Converting foreign characters into english
library(gsubfn)
#creating lift chart
#install.packages("gains")
library(gains)
#confusion matrix
library(caret)
View(data)
# Loading and cleaning the data
x <- readLines("netflix.csv")
data<- read.csv("netflix.csv", header =TRUE, sep=";")
getwd()
data<- read.csv("netflix.csv", header =TRUE, sep=";")
#Viewing complete dataset
View(data)
